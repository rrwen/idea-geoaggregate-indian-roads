---
title: "Geoaggregating Roads in India by States and Union Territories (UT)"
author: "Richard Wen <rrwen.dev@gmail.com>"
date: "`r format(Sys.time(), '%B %d, %Y')`"
site: bookdown::bookdown_site
output:
  bookdown::gitbook
---

```{r setup, include=F}
knitr::opts_chunk$set(echo = T)
```

# The Idea

Since I was interested in doing a traffic-related study of India, I wanted to know more about the general characteristics of Indian roads - particularly at the state/UT level. I am also mentoring a student for a brief internship (bright kid with great potential!), and wanted to introduce him to some spatial data handling in R, since he was interested in learning some data analysis.

Fortunately, [DIVA-GIS](https://www.diva-gis.org/) provides us with geospatial data of administrative boundaries and roads for free (all in one easily accessible website - pretty awesome!).

To implement this idea, I will be providing a brief walkthrough to geospatially aggregating (or geoaggregating) roads by state/Union Territory (UT). The aggregation will involve some spatial intersections, and polyline length/vertex extractions. For the sake of time (as it may be redundant and computationally expensive to process all the states/UTs for this walkthrough), we will play around with one state, but initially look at the entire dataset.

# Requirements

For this walkthrough we will be using the [R](https://www.r-project.org/) programming language.

You will need to install:

1. [R and RTools](https://www.r-project.org/) programming language and compiler tool
2. [R Studio](https://www.rstudio.com/) (*Suggested*) editor for easily working with R
3. [sf](https://cran.r-project.org/package=sf), [mapview](https://cran.r-project.org/package=mapview), [lwgeom](https://cran.r-project.org/package=lwgeom), and [units](https://cran.r-project.org/package=units) libraries in the R console (seen below)

```{r requirements-install, eval=F}
install.packages(c("sf", "lwgeom"))
```

## Overview of R Packages

[sf](https://cran.r-project.org/package=sf) is a very convenient and relatively user-friendly R package that provides tools for working with geometries - making it easy to read, write, and work with geospatial data.

[mapview](https://cran.r-project.org/package=mapview) provides interactive mapping functionality so we can inspect geospatial data in detail. For our particular purpose, it also provides a handy `npts` function that allows us to extract the number of vertices given a polygon or polyline.

[lwgeom](https://cran.r-project.org/package=lwgeom) is needed by sf to get the lengths of polylines and other geometric objects, so we will install it to satisfy the dependencies.

[units](https://cran.r-project.org/package=units) is package for converting and handling units of measurements. We will use this package to convert unit of measurements for our area calculations when deciding on a state/UT to use.

## Loading the R Libraries

After you have finished installing the requirements, don't forget to load the libraries in the R console!:

```{r requirements-library, message=F}
library(sf)
library(mapview)
```

**Note**: All code will be assumed to be in the R console moving forward.

After satisfying all of the requirements, the next section will show you how to get the DIVA-GIS data into R.

# Getting the DIVA-GIS Data

[DIVA-GIS](https://www.diva-gis.org/) provides free country level road and administrative boundary data for all of India, which can be conveniently accessed through the following links:

* **Administrative Boundaries** ([Download](http://biogeo.ucdavis.edu/data/diva/adm/IND_adm.zip))
* **Roads**: ([Download](http://biogeo.ucdavis.edu/data/diva/rds/IND_rds.zip))

These data are also sourced from [GADM](https://www.gadm.org/about.html), where the data can also be downloaded in additional formats [here](https://www.gadm.org/download_country_v3.html).

## Downloading the Data Automatically

You can download the data manually, but where's the fun in that? Lets make our code reproducible by making downloads automatic!

Notice that the data from the links are zip files, and need to first be unzipped to see its contents. To do that, we will:

1. Download the datasets into a folder called data
2. Unzip the downloaded files
3. Remove the zip files as they are no longer needed

```{r data-download, eval=F, warning=F}

# Create a folder called data
dir.create("data")

# Download the admin areas and roads
download.file("http://biogeo.ucdavis.edu/data/diva/adm/IND_adm.zip", "data/IND_adm.zip")
download.file("http://biogeo.ucdavis.edu/data/diva/rds/IND_rds.zip", "data/IND_rds.zip")

# Unzip the downloaded files
unzip("data/IND_adm.zip", exdir = "data/india-admin-areas")
unzip("data/IND_rds.zip", exdir = "data/india-roads")

# Remove the zip files
unlink(c("data/IND_adm.zip", "data/IND_rds.zip"))
```

## Inspecting the Data

We can now inspect each of the unzipped folders with the administrative area:

```{r data-inspect-admin}
list.files("data/india-admin-areas")
```

and the roads data:

```{r data-inspect-roads}
list.files("data/india-roads")
```

In the administrative area and roads data, there are 4 types of files (.cpg, .dbf, .shp, .prj, .shx), which correspond to character encoding files, database file, shapefile, projection system file, and a shape/font file used commonly by CAD. The main file we will be focusing on here is the shapefile (.shp), which is an [ESRI](https://www.esri.com/) (a well known Geographic Information Systems (GIS) company) [vector data](https://docs.qgis.org/latest/en/docs/gentle_gis_introduction/vector_data.html) format that is widely used in the field of GIS.

More details on shapefiles can be found [here](https://www.esri.com/library/whitepapers/pdfs/shapefile.pdf) from ESRI, and [here](https://gdal.org/drivers/vector/shapefile.html) from [gdal](https://gdal.org/).

## Reading the data into R

Now that we have some understanding of the file formats, we can try reading some of the files into R:

```{r data-read-try}
lvl0Data <- st_read("data/india-admin-areas/IND_adm0.shp")
```

When you read the data into R, it will provide you with some general information about the data:

* Number of features and fields (rows/geometric objects and columns/variables)
* Geometry type (point, polygon, linestring, and multi-variants of those)
* Dimension of the geometric data (2D XY or 3D XYZ)
* Bounding box (bbox) or the encompassing rectangular area of the data
* Spatial reference ID (epsg SRID) for defining the projection system used
* String defining additional parameters for the projection system

There are 29 states and 7 UTs in India for a total of 36 states/UTs ([knowindia.gov](https://knowindia.gov.in/states-uts/)), which means we should have 36 geometric objects in one of the datasets inside `data/india-admin-areas`.

Looks like the file `IND_adm0.shp` (level 0) only has `r nrow(lvl0Data)` feature, which is probably not the data level we are looking for.

Let's try the level 1 administrative areas next:

```{r data-read-lvl1}
lvl1Data <- st_read("data/india-admin-areas/IND_adm1.shp")
```

Hey, this looks like it could be the states/UTS! There are `r nrow(lvl1Data)` features (geometric objects) here, but just to be sure, lets check the level 2 and 3 data as well:

```{r data-read-lvl2}
lvl2Data <- st_read("data/india-admin-areas/IND_adm2.shp")
```

```{r data-read-lvl3}
lvl3Data <- st_read("data/india-admin-areas/IND_adm3.shp")
```

The level 2 data has `r nrow(lvl2Data)` features (a bit too much for states/UTs data), while the level 3 data has even more at `r nrow(lvl3Data)` features (far too many objects!).

So it looks like the level 1 data is what we are looking for! Let's map it to further inspect it (more on this in the next section):

```{r data-read-map}
plot(st_geometry(lvl1Data))
```

It was not a coincidence that level 1 had 36 features when we look at the map above!

To recap, we can see that there are levels 0 to 3 (larger less detailed boundaries at level 0 to smaller more refined boundaries at level 3). Since we are looking for state/UT boundaries (a total of 36), we will use level 1, which has 36 geometric features for our walkthrough.

**Note**: The associated state/UT names can also be extracted from the column `NAME_1` which refers to the names for level 1 administrative boundaries:

```{r data-read-names}
lvl1Data$NAME_1
```

## Reading the Data for Our Walkthrough

Based on the inspection above, go ahead and read the appropriate data into a sf object:

```{r data-inspect-variables}
roads <- st_read("data/india-roads/IND_roads.shp")
admin <- st_read("data/india-admin-areas/IND_adm1.shp")
```

The next section will focus on producing some basic maps for visual exploration.

# Visually and Interactively Exploring Our Data

Now that we have set `admin` to be the loaded administrative area data and `roads` to be the loaded roads data, we can use `sf` and `mapview` to plot their geometry on a static or interactive map.

## Static Mapping

Here we need to use `st_geometry` to generate our static maps on the geometries only, otherwise the `sf` objects will plot a map for every column of the dataset:

```{r visual-admin}
plot(st_geometry(admin), axes = T)
```

We chose to show the axis `axis = T`, giving a general idea of what coordinates each state/UT is located at. We also show the polygonal boundaries to give us a look at how large each state/UT is. Looks like there are relatively larger states/UTs near the northern center of India, while the south and western edges have smaller states/UTs.

```{r visual-roads}
plot(st_geometry(roads), axes = T)
```

Since road data is generally polylines, and we are using all roads without considering their classification (highways, streets, etc), we can simply plot just the lines. This gives us an idea of which areas in India have more roads (are more road dense) than that of others. We can see that most of the south and eastern areas in India are relatively denser (darker portions) than the other areas.

In addition to plotting a single dataset, we can also layer them on top of each other with `add = T`, change colors with `col`, and change polygon line (border) colors with `border`:

```{r visual-layers}
plot(st_geometry(roads), axes = T, col = "gray")
plot(st_geometry(admin), add = T, border = "red")
```

In the layered map, we can see that in some states/UTs in the eastern half (near the center) and southern portions of India have areas that are more road dense, while other areas are less road dense when we move towards the west.

## Web Mapping

In addition to static mapping, we can also use `mapview` to interactively explore our data. This will let us zoom, pan around, and click on geometric objects to explore them in detail.

It's pretty cool - try it out!:

```{r visual-interactive-admin}
mapview(admin, viewer.suppress = F)
```
  
  
Although we can view single datasets by themselves, they are often not too interesting until we layer them on top of another dataset. We do that by first creating an initial map `roadsMap`, then we add another map to it with the `map = roadsMap` option, which tells `mapView` which existing map the new map should be added to:

Finally, let's play around with some styling options and create a dark themed map!
  
```{r visual-interactive-layers}
# Create an interactive roads map
roadsMap <- mapview(roads, viewer.suppress = F, legend = F,
                    map.types = "CartoDB.DarkMatter",
                    color = "#d2d2d2",
                    alpha = 0.5, # transparency
                    layer.name = "Roads",
                    lwd = 0.75) # line width

# Add state/UT map to roads map
mapView(admin, map = roadsMap,
        color = "#f5f5f5",
        col.region = "#f5f5f5",
        alpha = 0.75,
        alpha.regions = 0, # remove polygon fill to see roads underneath
        layer.name = "States/UTs",
        lwd = 1)
```
  
  
As we saw before, particular regions have more "compact" roads or road density - notably the eastern half of India and towards the south. We can inspect some of the states in these areas further by clicking on them. Here a few states are worth noting as they are more "road dense" throughout their entire areas: Jharkhand, Tamil Nadu, Telangana, Karnataka, Chhattisgarh (to name a few). However, visual inspection can be a little subjective as it can be based on perspective and visual design - this is where doing some calculations with the data will help!

In the next section, we will use `sf`, `lwgeom`, and `mapview` to extract road lengths and vertices, and to geoaggregate them into a chosen state/UT to demonstrate some spatial processing.

# Extracting Road Lengths and Vertices

Ideally, we would want to apply the following approach for each state/UT to get the aggregate road lengths and vertices for all of India:

1. Get the roads that spatially intersect (approximately) the state/UT
2. Calculate the min/max/mean/sum lengths and vertices of intersecting roads
3. Add these calculated values to the admin data

The goal is to have road length and vertex statistics for each state/UT in India for a more numeric comparison between states/UTs, and possibly some more accurate maps. However, we will process only an average sized state in the dataset as the rest of the states/UTs will simply be repetitions of the approach above.

**Note 1:** The spatial intersection (first step of our approach) here may not be completely accurate as we are only checking for roads that intersect each state/UT, but we are not trimming/cutting long roads that lie inside a state/UT and extend partially outside of it.

**Note 2:** For simplicity, We have not projected the geographic coordinates (spherical coordinates measured from earth's center) into planar coordinates (projected geographic coordinates onto a 2D surface) so the intersection algorithm may also not be completely accurate when measuring distances to determine if roads intersect the state/UTs.

## Picking the State for Our Approach

We will look at the different areas of the states/UTs in kilometers squared, and pick a state closest to the average area as our selection criteria. The idea is to select a state with an average area so we have an idea how long it will roughly take to process one state of average size.

First, we can compute the areas in kilometers squared and add it to our administrative areas data `admin`, then plot it as a bar graph:

```{r extract-pick-area}
# Get areas in kilometers squared, covert to km squared and add it to the data
admin$area <- st_area(admin)
admin$area <- units::set_units(admin$area, "km^2") # convert to kilometers

# Sort the data by area
admin <- admin[order(-admin$area), ]

# Produce a bar plot of the state/UT names and their areas
x <- as.numeric(admin$area)
y <- admin$NAME_1
options(scipen=5) # Prevent scientific notation for our plot
par(mar=c(4, 6, 0, 1)) # Increase margins to fit plot
barplot(x, names.arg = y,
        horiz = T, las = 2, cex.names = 0.5, # hor. labels
        border = "white") # line color of bars
```

We can see from the graph that India has relatively even number of state/UTs of varying sizes from `r floor(min(admin$area))` kilometers squared to `r ceiling(max(admin$area))` kilometers squared.

Next, we want to get the state closest to the average size given all states/UTs in India. For reference, this will be the state/UT with an area that has the smallest absolute difference from the average state/UT area:

The mean can be calculated as:

$$
\bar{x} = \frac{x_1 + x_2 + x_3 \dots x_n}{n}
$$

where $\bar{x}$ is the average area of all state/UTs, $x_1 + x_2 + x_3 \dots x_n$ is the sum of the areas for a states 1 to `r nrow(admin)`, and $n$ is the number of states (`r nrow(admin)` in this case).

```{r extract-pick-mean}
x <- admin$area
xMean <- mean(x)
```

The absolute differences from the average area for each state/UT are then represented as a set $\{d_1, d_2, d_3 \dots d_n\}$ given by subtracting the state/UT areas $\{x_1, x_2, x_3, \dots x_n\}$ from the average area of all state/UTs $\bar{x}$:

$$
\{d_1, d_2, d_3 \dots d_n\} = | \{x_1, x_2, x_3, \dots x_n\} - \bar{x}|
$$

```{r extract-pick-diff}
d <- abs(x - xMean)
```

We then want the state/UT with the smallest difference from the set (the state/UT with an area closest to the average size of all states/UTs in India), stored in the variable `stateUT`:

$$
min(\{d_1, d_2, d_3 \dots d_n\})
$$

```{r extract-pick-min}
dMin <- min(d)
stateUT <- admin[which(d == dMin),]
```

Let's inspect the state/UT we picked from our selection criteria:

```{r extract-pick-inspect}
stateUT[, c("NAME_1", "area")]
```

We can see that we selected state/UT `r stateUT$NAME_1[[1]]`, with an area of about `r as.character(round(stateUT$area[[1]]))` kilometers squared, which is close to the average area of approximately `r as.character(round(xMean))` kilometers squared.

## Extracting Intersecting Roads

Now that we have chosen our state/UT, lets start the extraction by trying to get all the roads that intersect a single state/UT (since this is the start of the process, we also want to keep track of the processing time with `Sys.time`):

```{r extract-intersect, message=F, cache=T}
# Track the start time of our extraction process for a single state/UT
startTime1 <- Sys.time()

# Get intersecting roads for state/UT
inStateUT <- st_intersects(roads, stateUT, sparse = F)
stateUTRoads <- roads[inStateUT, ]

# Time for intersection processing
intersectTime <- Sys.time() - startTime1

# Plot the intersecting roads with the state/UT to check
plot(st_geometry(stateUT), axes = T, border = "red")
plot(st_geometry(stateUTRoads), add = T)
```

Looking at the plot, we can see that we have extracted the roads that touch or intersect the second state `r stateUT$NAME_1[[1]]`, but it does not actually trim or cut the roads when they extend past the state/UT borders. We can use `st_intersection` (will trim and only keep geometries that are inside the state/UT) for more accuracy, but the computation time would rise, so we will stick with `st_intersects` (only checks for TRUE or FALSE comparisons, but does not modify the geometries) for the purpose of this walkthrough.

## Calculating Road Lengths and Vertex Statistics

Lets move on and extract the min/max/mean/sum road lengths and vertices for `r stateUT$NAME_1[[1]]`:

```{r extract-stats, cache=T}
# Track the time it takes for calculating road lengths and vertices
startTime2 <- Sys.time()

# Extract the length stats
stateUTRoadsLength <- st_length(stateUTRoads)
stateUTLengthStats <- c(min(stateUTRoadsLength, na.rm = T),
                        max(stateUTRoadsLength, na.rm = T),
                        mean(stateUTRoadsLength, na.rm = T),
                        sum(stateUTRoadsLength, na.rm = T))
stateUTLengthStats <- as.numeric(stateUTLengthStats)

# Extract the vertices stats
stateUTRoadsVertex <- npts(stateUTRoads, by_feature = T)
stateUTVertexStats <- c(min(stateUTRoadsVertex, na.rm = T),
                        max(stateUTRoadsVertex, na.rm = T),
                        mean(stateUTRoadsVertex, na.rm = T),
                        sum(stateUTRoadsVertex, na.rm = T))
stateUTVertexStats <- as.numeric(stateUTVertexStats)

# Time for calculating lengths and vertices
calcTime <- Sys.time() - startTime2

# Combine the stats and name them
stateUTStats <- c(stateUTLengthStats, stateUTVertexStats)
names(stateUTStats) <- c("min_length_meters",
                         "max_length_meters",
                         "mean_length_meters",
                         "sum_length_meters",
                         "min_vertices_meters",
                         "max_vertices_meters",
                         "mean_vertices_meters",
                         "sum_vertices_meters")
print(stateUTStats)
```

## Adding Statistics to the State/UT

Finally, we can add the calculated road lengths and vertex statistics to the state/UT `r stateUT$NAME_1[[1]]` by converting it into a dataframe, adding the statistics, and then converting it back into a sf object:

```{r extract-add, cache=T}
# Add the stats to the single state/UT
stateUT <- data.frame(stateUT)
stateUT[, names(stateUTStats)] <- stateUTStats
stateUT <- st_sf(stateUT)

# Interactively view the results
mapview(stateUT, viewer.suppress = F)
```
  
  
Click on the state, and you will now notice that there are extra data on the road length and vertex statistics added to it. If we had done this for all the other states/UTs, we can compare them using numbers, and highlight states/UTs with road densities that are higher than normal to give a better visual representation of our data, but for now we have shown that we can indeed process one state/UT in a reasonable amount of time, and can repeat this process for all the other 35 states/UTs.

## Reviewing the Processing Times for Extraction

Now that we have extracted the road lengths and vertices for the state, we can check how long it took us approximately to process the steps. Remember that we tracked the intersection processing time `intersectTime` and road length/vertices calculation time `calcTime`.

Lets have a look at these:

```{r extract-times}
# Calculate the total processing time
totalTime <- intersectTime + calcTime

# Display the processing times
cat("Spatial Intersection:", format(intersectTime, usetz = T),
    "\nRoad Length/Vertices Calculation Time:", format(calcTime, usetz = T),
    "\nTotal Time:", format(totalTime, usetz = T))
```

We can see that the total time for our extraction approach is `r format(totalTime, usetz = T)`, which could roughly be more or less `r format(totalTime, usetz = T)` multiplied by `r nrow(admin)` (the number of state/UTs) for an estimate of `r format(totalTime * nrow(admin), usetz=T)`. This could scale to much larger processing times if we were to use more detailed data, or if we were to use smaller levels of administrative boundaries/geometries of interest. However, processing one state/UT will give us a good idea of how long it will take to process all states/UTs.

**Note:** We did not consider the min/max/mean/sum calculations that may factor into the time and the addition of the calculated statistics into the `admin` dataset, but they generally should not take too much processing time.

# Ending Off with a Few Thoughts

We started with the idea to extract a number of informative aggregate characteristics of roads in India by state/UT, but found that there may be some issues with accuracy (coordinate system and trimming near state/UT boundaries) and computation time (time it took to process one state/UT).

Ideally, we should project each state/UT to an appropriate planar coordinate system to achieve more accurate spatial intersection results. There should probably also be a good amount of trimming/cutting involved as roads tend to be partially outside the boundaries of the states/UTs.

Although the data was only a few megabytes, the computation time was roughly `r format(round(totalTime, digits = 2), usetz = T)` minutes for the single state/UT, estimated to be `r format(round(totalTime * nrow(admin), digits = 2), usetz = T)` for all state/UTs. This could be problematic as we receive finer boundary or road data, and scale to larger more detailed datasets.

Some exploration into optimizing the spatial intersections and trimming/cutting could be a good start to obtaining quicker results in a reasonable amount of time (especially for learning or education).

Getting the road lengths and vertices statistics could be useful (as far as I can tell) in providing information on road complexity and development. This could be a potentially good measure for getting a glimpse at the general road design at a state/UT level, while providing some insight into whether or not road design at that level has an effect on important applications such as road traffic safety.

Overall, R has proven to be great for trying out ideas, experimenting with new libraries, and providing an easier transition into open source data analysis for those unfamiliar with spatial data handling - particularly when `install.packages` just works without any hiccups on windows!

I am hoping to take this idea a little further and apply it to study traffic crashes in India, and perhaps refine this walkthrough so it becomes a little more beginner friendly.

It was a lot of fun to write this and I'm hoping to try out some more ideas/thoughts when I have time!
